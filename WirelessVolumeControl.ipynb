{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sympy  import re \n",
    "import  math\n",
    "import  numpy as np\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "print(volume.GetMute(),\"\\n\")\n",
    "print(volume.GetMasterVolumeLevel(),\"\\n\")\n",
    "print(volume.GetVolumeRange(),\"\\n\")\n",
    "volume.SetMasterVolumeLevel(0.0,None)\n",
    "\n",
    "from mediapipe.python.solutions.drawing_utils import draw_landmarks\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, image= cap.read()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handLms in results.multi_hand_landmarks:\n",
    "            lmList = []\n",
    "            for id, lm in enumerate(handLms.landmark):\n",
    "                print(id, lm)\n",
    "                h, w, c = image.shape\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                print(id, cx, cy)\n",
    "                lmList.append([id, cx, cy])\n",
    "                print(lmList)\n",
    "            if lmList:\n",
    "                x1, y1=lmList[4][1], lmList[4][2]\n",
    "                x2,y2=lmList[8][1],lmList[8][2]\n",
    "                cv2.circle(image,(x1,y1),15,(134,23,42),cv2.FILLED)\n",
    "                cv2.circle(image,(x2,y2),15,(134,23,42),cv2.FILLED)\n",
    "                cv2.line(image,(x1,y1),(x2,y2),(2,45,123),5)\n",
    "                length = math.hypot(x2-x1, y2-y1)\n",
    "                print(length)\n",
    "                if length<50:\n",
    "                    z1 = (x1+x2)//2\n",
    "                    z2 = (y1+y2)//2\n",
    "                    cv2.circle(image,(z1,z2),25,(4,123,142),cv2.FILLED)\n",
    "\n",
    "            volRange = volume.GetVolumeRange()\n",
    "            minVol = volRange[0]\n",
    "            maxVol = volRange[1]\n",
    "            vol = np.interp(length, [50,300], [minVol, maxVol])\n",
    "            volBar = np.interp(length, [50,300], [400,150])\n",
    "            volPer = np.interp(length, [50,300], [0,100])\n",
    "\n",
    "            \n",
    "            volume.SetMasterVolumeLevel(vol,None)\n",
    "            cv2.rectangle(image , (50,150), (89,400) , (123,213,122) ,3)\n",
    "            cv2.rectangle(image , (50,int(volBar)), (85,400) , (0,231,23) ,cv2.FILLED)\n",
    "            cv2.putText(image , str(int(volPer)), (40,450), cv2.FONT_HERSHEY_PLAIN, 4, (24,34,34), 3)\n",
    "            \n",
    "            \n",
    "            mp_drawing.draw_landmarks(image, handLms, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "    cv2.imshow(\"Hand\",image)\n",
    "    cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
